{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import pandas as pd\n",
    "# import numpy as np \n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputd = pd.read_pickle(\"./dataset/file.pkl\")\n",
    "# #lastnp = np.load(\"file.pkl\",allow_pickle=True)\n",
    "# X_centerIMG =  np.array(inputd[\"centerimg\"].tolist()) # M , width , height\n",
    "# X_leftIMG = np.array(inputd[\"leftimg\"].tolist())\n",
    "# X_rightIMG = np.array(inputd[\"rightimg\"].tolist())\n",
    "# Y_throttle = np.array(inputd[\"throttle\"])\n",
    "# Y_steering = np.array(inputd[\"steering\"])\n",
    "# Y_reverse = np.array(inputd[\"reverse\"])\n",
    "# Y_speed = np.array(inputd[\"speed\"]) #*\n",
    "\n",
    "# Y = np.vstack((Y_throttle,Y_steering,Y_reverse)).T # M , 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputd.iloc[:,3:].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_centerIMG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_center_tensor =  torch.tensor(X_centerIMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_center_tensor.shape\n",
    "# type(X_center_tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After knowing pytorch datasets module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "from torchvision import transforms,utils\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RacingCarsDataset(Dataset):\n",
    "    def __init__(self,csv_file,transform=None):\n",
    "        self.frame = pd.read_pickle(csv_file)\n",
    "        #self.frame.drop([\"reverse\"],axis= 1)\n",
    "        self.centerimg =torch.Tensor(np.array(self.frame[\"centerimg\"].tolist(),dtype=np.float32)) # M , width , height\n",
    "        self.leftimg = torch.Tensor(np.array(self.frame[\"leftimg\"].tolist(),dtype=np.float32))\n",
    "        self.rightimg = torch.Tensor(np.array(self.frame[\"rightimg\"].tolist(),dtype=np.float32)) \n",
    "        Y_throttle = np.array(self.frame[\"throttle\"],dtype=np.float32)\n",
    "        Y_steering = np.array(self.frame[\"steering\"],dtype=np.float32)\n",
    "        Y_reverse = np.array(self.frame[\"reverse\"],dtype=np.float32)\n",
    "        Y_speed = np.array(self.frame[\"speed\"],dtype=np.float32) #*\n",
    "        self.Y = torch.Tensor(np.vstack((Y_throttle,Y_steering,Y_reverse),dtype=np.float32).T)\n",
    "        self.transform=transform\n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index=index.tolist()\n",
    "        centerimg = self.centerimg[index]\n",
    "        centerimg =centerimg.reshape((*centerimg.shape,1))\n",
    "        centerimg=np.array(centerimg.tolist())\n",
    "        leftimg = self.leftimg[index]\n",
    "        leftimg =leftimg.reshape((*leftimg.shape,1))\n",
    "        leftimg=np.array(leftimg.tolist())\n",
    "        rightimg = self.rightimg[index]\n",
    "        rightimg =rightimg.reshape((*rightimg.shape,1))\n",
    "        rightimg=np.array(rightimg.tolist())\n",
    "        outputs=self.Y[index]\n",
    "        #outputs=outputs.reshape((*outputs.shape,1))\n",
    "        sample = {\"center\": centerimg,\"left\": leftimg,\"right\": rightimg, \"outputs\":outputs}\n",
    "        if self.transform != None:\n",
    "            sample[\"center\"] = self.transform(sample[\"center\"])\n",
    "            sample[\"left\"] = self.transform(sample[\"left\"])\n",
    "            sample[\"right\"] = self.transform(sample[\"right\"])\n",
    "            #sample[\"outputs\"] = self.transform(outputs)\n",
    "        return sample \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = RacingCarsDataset(\"./dataset/file.pkl\")\n",
    "fig, axs = plt.subplots(nrows=4, ncols=3, figsize=(12,4))\n",
    "for i,sample in enumerate(rd):\n",
    "    print(i,sample['center'].shape,sample['left'].shape,sample['right'].shape,sample[\"outputs\"])\n",
    "\n",
    "    \n",
    "    plt.sca(axs[i][0])\n",
    "    plt.imshow(sample['left'],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.sca(axs[i][1])\n",
    "    plt.imshow(sample['center'],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.sca(axs[i][2])\n",
    "    plt.imshow(sample['right'],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if i==3 : \n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self,sample):\n",
    "        center,left,right,Y = sample.values()\n",
    "        print(center.shape,left.shape,right.shape,sep='\\n')\n",
    "        center=center.transpose((2,0,1))\n",
    "        left=left.transpose((2,0,1))\n",
    "        right=right.transpose((2,0,1))\n",
    "        return {\"center\": torch.Tensor(center),\"left\": torch.Tensor(left),\"right\": torch.Tensor(right), \"outputs\":torch.Tensor(Y)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=12\n",
    "M = 6828\n",
    "num_epochs = 10\n",
    "height=160\n",
    "width=320\n",
    "from torchvision import transforms\n",
    "training_dataset = RacingCarsDataset(\"./dataset/file.pkl\",transform=transforms.Compose([transforms.ToTensor()]))\n",
    "training_dataset_loader = DataLoader(training_dataset,batch_size=batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "input_channel=1\n",
    "hidden_channel=64\n",
    "output_channel=128\n",
    "learning_rate =0.01\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self,input_channels,hidden_channels,output_channels,hidden_layer):\n",
    "        super(Model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels,out_channels=hidden_channels,kernel_size=3) \n",
    "        self.conv2 = nn.Conv2d(in_channels=hidden_channels,out_channels=output_channels,kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(output_channels)\n",
    "        self.fc1 = nn.Linear(379392,hidden_layer)\n",
    "        self.fc2 = nn.Linear(hidden_layer,3)\n",
    "        self.max1=nn.MaxPool2d(2,2)\n",
    "        self.max2=nn.MaxPool2d(2,2)\n",
    "    def forward(self,input):\n",
    "        input = self.bn1(self.max1(self.conv1(input)))\n",
    "        input = self.bn2(self.max2(self.conv2(input)))\n",
    "        input = input.view(-1, self.num_flat_features(input))\n",
    "        #print(input.shape)\n",
    "        input = self.fc1(input)\n",
    "        input = self.fc2(input)\n",
    "        return input\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 17289.233\n",
      "[2] loss: 28.763\n",
      "[3] loss: 120.279\n",
      "[4] loss: 0.063\n",
      "[5] loss: 0.106\n",
      "[6] loss: 190.115\n",
      "[7] loss: 180863.902\n",
      "[8] loss: 11.688\n",
      "[9] loss: 5.705\n",
      "[10] loss: 3.543\n"
     ]
    }
   ],
   "source": [
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "m = Model(input_channel,hidden_channel,output_channel,125).to(device)\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "n_total_steps = len(training_dataset_loader)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, sample in enumerate(training_dataset_loader):\n",
    "        centerimg = sample[\"center\"].to(device, dtype=torch.float32)\n",
    "        labels = sample[\"outputs\"].to(device, dtype=torch.float32)\n",
    "        #print(centerimg.shape)\n",
    "        # Forward pass\n",
    "        outputs = m(centerimg)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    if (epoch % 10) == 0:\n",
    "        torch.save(Model, f'model{epoch/10}.pth')\n",
    "    print(f'[{epoch + 1}] loss: {running_loss / n_total_steps:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Model, 'modellast.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=379392, out_features=125, bias=True)\n",
       "  (fc2): Linear(in_features=125, out_features=3, bias=True)\n",
       "  (max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (max2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = torch.load('./modellast.pt')\n",
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "l = loaded_model(1,64,128,125).to(device)\n",
    "l.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of the loaded model on saved model: 2710.649658203125 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataset = RacingCarsDataset(\"./dataset/test.pkl\",transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_dataset_loader = DataLoader(test_dataset,batch_size=12,shuffle=True)\n",
    "with torch.no_grad():\n",
    "    n_correct2 = 0\n",
    "    n_samples = len(test_dataset_loader.dataset)\n",
    "    MSE=nn.MSELoss()\n",
    "    for i,sample in enumerate(test_dataset_loader):\n",
    "        images = sample[\"center\"].to(device,dtype=torch.float32)\n",
    "        labels = sample[\"outputs\"].to(device,dtype=torch.float32)\n",
    "        #outputs = model(images)\n",
    "\n",
    "        # max returns (value ,index)\n",
    "        #n_correct += (outputs == labels).sum().item()\n",
    "\n",
    "        outputs2 = l(images)\n",
    "        n_correct2 +=MSE(outputs2,labels)\n",
    "\n",
    "    #acc = 100.0 * n_correct / n_samples\n",
    "    #print(f'Accuracy of the model: {acc} %')\n",
    "\n",
    "    acc = 100.0 * n_correct2 / n_samples\n",
    "    print(f'Average loss of the loaded model on saved model: {acc} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
